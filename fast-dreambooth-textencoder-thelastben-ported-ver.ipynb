{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/robertodefano/fast-dreambooth-textencoder-thelastben-ported-ver?scriptVersionId=111884174\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive/MyDrive","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/TheLastBen/diffusers\n!pip install -q git+https://github.com/TheLastBen/diffusers\n!pip install -q accelerate==0.12.0\n!pip install -q OmegaConf\n!pip install -q wget\n!pip install -q pytorch_lightning\n!pip install -q huggingface_hub\n!pip install -U -q --no-cache-dir gdown\n!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv Deps Deps.7z\n!7z x Deps.7z","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /usr/local/lib/python3.7","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /usr/local/lib/python3.7/dist-packages","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/working/content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm /kaggle/working/content/Deps.7z\n!rm -r /kaggle/working/content/usr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wget","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@markdown # xformers\n\nfrom subprocess import getoutput\nfrom IPython.display import HTML\nfrom IPython.display import clear_output\nimport wget\nimport time\n\ns = getoutput('nvidia-smi')\nif 'T4' in s:\n  gpu = 'T4'\nelif 'P100' in s:\n  gpu = 'P100'\nelif 'V100' in s:\n  gpu = 'V100'\nelif 'A100' in s:\n  gpu = 'A100'\n\nwhile True:\n    try: \n        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n        break\n    except:\n        pass\n    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n    time.sleep(5)\n\nif (gpu=='T4'):\n  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n  \nelif (gpu=='P100'):\n  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n\nelif (gpu=='V100'):\n  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n\nelif (gpu=='A100'):\n  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n\nclear_output()\nprint('\u001b[1;32mDONE !')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working/content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install git-lfs\n!git lfs install","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nfrom IPython.display import clear_output\nfrom IPython.utils import capture\n\n#@markdown - Skip this cell if you are loading a previous session\n\n#@markdown ---\n\nwith capture.capture_output() as cap: \n  %cd /kaggle/working/content/\n\nHuggingface_Token = \"your_huggingface_token\" #@param {type:\"string\"}\ntoken=Huggingface_Token\n\n#@markdown (Make sure you've accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5)\n\n#@markdown ---\n\n#@markdown Or\n\nPath_to_HuggingFace= \"\" #@param {type:\"string\"}\n\n#@markdown - Load and finetune a model from Hugging Face, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n\n#@markdown Or\n\nCKPT_Path = \"\" #@param {type:\"string\"}\n\n#@markdown Or\n\nCKPT_Link = \"\" #@param {type:\"string\"}\n\n#@markdown - A CKPT direct link, huggingface CKPT link or a shared CKPT from gdrive.\n#@markdown ---\n\nCompatibility_Mode=\"\" #@param {type:\"boolean\"}\n#@markdown - Enable only if you're getting conversion errors.\n\n\ndef downloadmodel():\n  token=Huggingface_Token\n  if token==\"\":\n      token=input(\"Insert your huggingface token :\")\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n  clear_output()\n\n  %cd /kaggle/working/content/\n  clear_output()\n  !mkdir /kaggle/working/content/stable-diffusion-v1-5\n  %cd /kaggle/working/content/stable-diffusion-v1-5\n  !git init\n  !git lfs install --system --skip-repo\n  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n  !git config core.sparsecheckout true\n  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n  !git pull origin main\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n    !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n    !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n    %cd /kaggle/working/content/stable-diffusion-v1-5    \n    !rm model_index.json\n    time.sleep(1)    \n    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n    !sed -i 's@\"clip_sample\": false@@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /kaggle/working/content/stable-diffusion-v1-5/vae/config.json  \n    %cd /kaggle/working/content/    \n    clear_output()\n    print('\u001b[1;32mDONE !')\n  else:\n    while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n         time.sleep(5)\n\ndef downloadmodel_hf():\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n  clear_output()\n\n  %cd /kaggle/working/content/\n  clear_output()\n  !mkdir /kaggle/working/content/stable-diffusion-v1-5\n  %cd /kaggle/working/content/stable-diffusion-v1-5\n  !git init\n  !git lfs install --system --skip-repo\n  !git remote add -f origin  \"https://USER:{token}@huggingface.co/{Path_to_HuggingFace}\"\n  !git config core.sparsecheckout true\n  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n  !git pull origin main\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n    !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n    !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n    %cd /kaggle/working/content/stable-diffusion-v1-5    \n    !rm model_index.json\n    time.sleep(1)\n    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n    !sed -i 's@\"clip_sample\": false@@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /kaggle/working/content/stable-diffusion-v1-5/vae/config.json    \n    %cd /kaggle/working/content/    \n    clear_output()\n    print('\u001b[1;32mDONE !')\n  else:\n    while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n         print('\u001b[1;31mCheck the link you provided')\n         time.sleep(5)\n\nif Path_to_HuggingFace != \"\":\n  downloadmodel_hf()\n\nelif CKPT_Path !=\"\":\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n  if os.path.exists(str(CKPT_Path)):\n    !mkdir /kaggle/working/content/stable-diffusion-v1-5\n    with capture.capture_output() as cap:\n      if Compatibility_Mode:\n        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n        !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-v1-5\n        !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n      else:           \n        !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-v1-5        \n    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n      !rm /kaggle/working/content/v1-inference.yaml\n      clear_output()\n      print('\u001b[1;32mDONE !')\n    else:\n      !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n      !rm /kaggle/working/content/v1-inference.yaml\n      !rm -r /kaggle/working/content/stable-diffusion-v1-5\n      while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n        print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n        time.sleep(5)\n  else:\n    while not os.path.exists(str(CKPT_Path)):\n       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n       time.sleep(5)\n\n\nelif CKPT_Link !=\"\":   \n    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n      !rm -r /kaggle/working/content/stable-diffusion-v1-5     \n    !gdown --fuzzy $CKPT_Link -O model.ckpt    \n    if os.path.exists('/kaggle/working/content/model.ckpt'):\n      if os.path.getsize(\"/kaggle/working/content/model.ckpt\") > 1810671599:\n        !mkdir /kaggle/working/content/stable-diffusion-v1-5\n        with capture.capture_output() as cap: \n          if Compatibility_Mode:\n            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n            !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-v1-5\n            !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py            \n          else:           \n            !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-v1-5\n        if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n          clear_output()\n          print('\u001b[1;32mDONE !')\n          !rm /kaggle/working/content/v1-inference.yaml\n          !rm /kaggle/working/content/model.ckpt\n        else:\n          if os.path.exists('/kaggle/working/content/v1-inference.yaml'):\n            !rm /kaggle/working/content/v1-inference.yaml\n          !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n          !rm -r /kaggle/working/content/stable-diffusion-v1-5\n          !rm /kaggle/working/content/model.ckpt\n          while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n            print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n            time.sleep(5)\n      else:\n        while os.path.getsize('/kaggle/working/content/model.ckpt') < 1810671599:\n           print('\u001b[1;31mWrong link, check that the link is valid')\n           time.sleep(5)\nelse:\n  downloadmodel()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/instance_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/Regularization_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom IPython.display import clear_output\nfrom IPython.utils import capture\nimport wget\nimport time\n\n#@markdown #Create/Load a Session\n\ndef fdownloadmodel():\n    token=input(\"Insert your huggingface token :\")\n    %cd /kaggle/working/content/\n    clear_output()\n    !mkdir /kaggle/working/content/stable-diffusion-v1-5\n    %cd /kaggle/working/content/stable-diffusion-v1-5\n    !git init\n    !git lfs install --system --skip-repo\n    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n    !git config core.sparsecheckout true\n    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n    !git pull origin main\n    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n      !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n      !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n      !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n      %cd /kaggle/working/content/    \n      !rm model_index.json\n      time.sleep(1)    \n      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n      !sed -i 's@\"clip_sample\": false@@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n      !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n      !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /kaggle/working/content/stable-diffusion-v1-5/vae/config.json  \n      %cd /kaggle/working/content/    \n      clear_output()\n      print('\u001b[1;32mDONE !')\n    else:\n      while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n           print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n           time.sleep(5)\n\nMODEL_NAME=\"/kaggle/working/content/stable-diffusion-v1-5\"\nPT=\"\"\n\nCaptionned_instance_images = True\n\nSession_Name = \"your_instance_name\" #@param{type: 'string'}\nwhile Session_Name==\"\":\n  print('\u001b[1;31mInput the Session Name:') \n  Session_Name=input('')\nSession_Name=Session_Name.replace(\" \",\"_\")\n\n#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n\nSession_Link_optional = \"\" #@param{type: 'string'}\n\n#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n\nWORKSPACE='/kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth'\n\nif Session_Link_optional !=\"\":\n  print('\u001b[1;32mDownloading session...')\nwith capture.capture_output() as cap:\n  %cd /kaggle/working/content\n  if Session_Link_optional != \"\":\n    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n      %mkdir -p $WORKSPACE'/Sessions'\n      time.sleep(1)\n    %cd $WORKSPACE'/Sessions'\n    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n    %cd $Session_Name\n    !rm -r instance_images\n    !rm -r Regularization_images\n    !unzip instance_images.zip\n    !mv *.ckpt $Session_Name\".ckpt\"\n    %cd /kaggle/working/content\n\n    \nINSTANCE_NAME=Session_Name    \nOUTPUT_DIR=\"/kaggle/working/content/models/\"+Session_Name\nSESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\nINSTANCE_DIR=SESSION_DIR+'/instance_images'\nMDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\nCLASS_DIR=SESSION_DIR+'/Regularization_images'\n\nContains_faces = \"No\" #@param [\"No\", \"Female\", \"Male\", \"Both\"]\n\ndef reg():\n  with capture.capture_output() as cap:\n    if Contains_faces!=\"No\":\n      if not os.path.exists(str(CLASS_DIR)):\n        %mkdir -p \"$CLASS_DIR\"\n      %cd $CLASS_DIR\n      !rm -r Women Men Mix\n      !wget -O Womenz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Women'\n      !wget -O Menz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Men'\n      !wget -O Mixz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Mix'\n      !unzip Menz\n      !unzip Womenz\n      !unzip Mixz\n      !rm Menz Womenz Mixz\n      !find . -name \"* *\" -type f | rename 's/ /_/g'\n      %cd /kaggle/working/content\n            \n#@markdown - If you're training on a subject with a face or a movie/style that contains faces. (experimental, still needs some tuning) \n\nif os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n  print('\u001b[1;32mLoading session with no previous model, using the original model')\n  reg()\n  if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n      !rm -r '/kaggle/working/content/stable-diffusion-v1-5'    \n    fdownloadmodel()\n  if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n    print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')\n  else:\n    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n\nelif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n  print('\u001b[1;32mSession found, loading the trained model ...')\n  reg()\n  %mkdir -p \"$OUTPUT_DIR\"\n  !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\" --session_dir \"$SESSION_DIR\"\n  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n    resume=True    \n    !rm /kaggle/working/content/v1-inference.yaml\n    clear_output()\n    print('\u001b[1;32mSession loaded.')\n  else:     \n    !rm /kaggle/working/content/v1-inference.yaml\n    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n\n\nelif not os.path.exists(str(SESSION_DIR)):\n    %mkdir -p \"$INSTANCE_DIR\"\n    print('\u001b[1;32mCreating session...')\n    reg()\n    if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n      if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n        !rm -r '/kaggle/working/content/stable-diffusion-v1-5'\n      fdownloadmodel()\n    if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n      print('\u001b[1;32mSession created, proceed to uploading instance images')\n    else:\n      print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n    \nif Contains_faces == \"Female\":\n  CLASS_DIR=CLASS_DIR+'/Women'\nif Contains_faces == \"Male\":\n  CLASS_DIR=CLASS_DIR+'/Men'\nif Contains_faces == \"Both\":\n  CLASS_DIR=CLASS_DIR+'/Mix'\n\ntry:\n  Contain_f\n  del Contain_f\nexcept:\n  pass\n\n    #@markdown \n\n    #@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n    #@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n    #@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/your_images_data_folder /kaggle/working/my","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@markdown #Instance Images\n#@markdown ----\n\n#@markdown\n#@markdown - Run the cell to Upload the instance pictures.\n\nRemove_existing_instance_images= True #@param{type: 'boolean'}\n#@markdown - Uncheck the box to keep the existing instance images.\n\n\nif Remove_existing_instance_images:\n  if os.path.exists(str(INSTANCE_DIR)):\n    !rm -r \"$INSTANCE_DIR\"\n\nif not os.path.exists(str(INSTANCE_DIR)):\n  %mkdir -p \"$INSTANCE_DIR\"\n\nIMAGES_FOLDER_OPTIONAL=\"/kaggle/working/my\" #@param{type: 'string'}\n\n#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n\nCrop_images= True #@param{type: 'boolean'}\nCrop_size = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\nCrop_size=int(Crop_size)\n\n#@markdown - Unless you want to crop them manually in a precise way, you don't need to crop your instance images externally.\n\nwhile IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n  IMAGES_FOLDER_OPTIONAL=input('')\n\nif IMAGES_FOLDER_OPTIONAL!=\"\":\n  if Crop_images:\n    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n      extension = filename.split(\".\")[1]\n      identifier=filename.split(\".\")[0]\n      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n      width, height = file.size\n      if file.size !=(Crop_size, Crop_size):      \n        side_length = min(width, height)\n        left = (width - side_length)/2\n        top = (height - side_length)/2\n        right = (width + side_length)/2\n        bottom = (height + side_length)/2\n        image = file.crop((left, top, right, bottom))\n        image = image.resize((Crop_size, Crop_size))\n        if (extension.upper() == \"JPG\"):\n            image.save(new_path_with_file, format=\"JPEG\", quality = 100)\n        else:\n            image.save(new_path_with_file, format=extension.upper())\n      else:\n        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n\n  else:\n    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n \n  print('\\n\u001b[1;32mDone, proceed to the training cell')\n\n\nelif IMAGES_FOLDER_OPTIONAL ==\"\":\n  uploaded = files.upload()\n  if Crop_images:\n    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n      shutil.move(filename, INSTANCE_DIR)\n      extension = filename.split(\".\")[1]\n      identifier=filename.split(\".\")[0]\n      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n      file = Image.open(new_path_with_file)\n      width, height = file.size\n      if file.size !=(Crop_size, Crop_size):        \n        side_length = min(width, height)\n        left = (width - side_length)/2\n        top = (height - side_length)/2\n        right = (width + side_length)/2\n        bottom = (height + side_length)/2\n        image = file.crop((left, top, right, bottom))\n        image = image.resize((Crop_size, Crop_size))\n        if (extension.upper() == \"JPG\"):\n            image.save(new_path_with_file, format=\"JPEG\", quality = 100)\n        else:\n            image.save(new_path_with_file, format=extension.upper())\n      else:\n          image.save(new_path_with_file, format=extension.upper())\n      clear_output()\n  else:\n    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n      shutil.move(filename, INSTANCE_DIR)\n      clear_output()\n\n  print('\\n\u001b[1;32mDone, proceed to the training cell')\n\nwith capture.capture_output() as cap:\n  %cd \"$INSTANCE_DIR\"\n  !find . -name \"* *\" -type f | rename 's/ /-/g'\n  %cd /content\n  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"    \n\n  %cd $SESSION_DIR\n  !rm instance_images.zip\n  !zip -r instance_images instance_images\n  %cd /kaggle/working/content","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install ftfy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install bitsandbytes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/content/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ftfy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@markdown ---\n#@markdown #Start DreamBooth\n#@markdown ---\nimport os\nfrom subprocess import getoutput\nfrom IPython.display import HTML\nfrom IPython.display import clear_output\nimport random\n\nResume_Training = False #@param {type:\"boolean\"}\n\nif not Resume_Training and not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n    !rm -r '/kaggle/working/content/stable-diffusion-v1-5'\n  print('\u001b[1;31mOriginal model not found, downloading....\u001b[0m')\n  fdownloadmodel()\n  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n     print('\u001b[1;32mModel downloaded, proceeding to training...')\n  else:\n     print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n\n#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n\nMODELT_NAME=MODEL_NAME\n\nTraining_Steps=3000 #@param{type: 'number'}\n#@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n\nSeed='' #@param{type: 'number'}\n\n#@markdown - Leave empty for a random seed.\n\nResolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\nRes=int(Resolution)\n\n#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n\nReduce_memory_usage = False #@param {type:\"boolean\"}\n\nfp16 = True #@param {type:\"boolean\"}\n\n#@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n\nGC= \"\"\nif Reduce_memory_usage:\n  GC= \"--gradient_checkpointing\"\n\nif Seed =='' or Seed=='0':\n  Seed=random.randint(1, 999999)\nelse:\n  Seed=int(Seed)\n\nif fp16:\n  prec=\"fp16\"\nelse:\n  prec=\"no\"\n\nprecision=prec\n\ntry:\n   resume\n   if resume and not Resume_Training:\n     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n     while True:\n        ansres=input('')\n        if ansres=='no':\n          Resume_Training = True\n          del ansres\n          break\n        elif ansres=='yes':\n          Resume_Training = False\n          resume= False\n          break\nexcept:\n  pass\n\nif Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n  MODELT_NAME=OUTPUT_DIR\n  print('\u001b[1;32mResuming Training...\u001b[0m')\nelif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n  MODELT_NAME=MODEL_NAME\n\n#@markdown ---------------------------\n\ntry:\n   Contain_f\n   pass\nexcept:\n   Contain_f=Contains_faces\n\nEnable_text_encoder_training= True #@param{type: 'boolean'}\n\n#@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n#@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n\n#@markdown - Enter the % of the total steps for which to train the text_encoder\nTrain_text_encoder_for=100 #@param{type: 'number'}\n\n#@markdown - Keep the % low for better style transfer, more training steps will be necessary for good results.\n#@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize, \n\nif Train_text_encoder_for>=100:\n  stptxt=Training_Steps\nelif Train_text_encoder_for==0:\n  Enable_text_encoder_training= False\n  stptxt=10\nelse:\n  stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n\nif not Enable_text_encoder_training:\n  Contains_faces=\"No\"\nelse:\n   Contains_faces=Contain_f\n\nif Enable_text_encoder_training:\n  Textenc=\"--train_text_encoder\"\nelse:\n  Textenc=\"\"\n\n#@markdown ---------------------------\nSave_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\nSave_Checkpoint_Every=500 #@param{type: 'number'}\nif Save_Checkpoint_Every==None:\n  Save_Checkpoint_Every=1\n#@markdown - Minimum 200 steps between each save.\nstp=0\nStart_saving_from_the_step=500 #@param{type: 'number'}\nif Start_saving_from_the_step==None:\n  Start_saving_from_the_step=0\nif (Start_saving_from_the_step < 200):\n  Start_saving_from_the_step=Save_Checkpoint_Every\nstpsv=Start_saving_from_the_step\nif Save_Checkpoint_Every_n_Steps:\n  stp=Save_Checkpoint_Every\n#@markdown - Start saving intermediary checkpoints from this step.\n\nCaption=''\nif Captionned_instance_images:\n  Caption='--image_captions_filename'\n\n\ndef txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n  print('\u001b[1;33mTraining the text encoder with regularization...\u001b[0m')\n  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n    $Caption \\\n    --train_text_encoder \\\n    --dump_only_text_encoder \\\n    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n    --instance_data_dir=\"$INSTANCE_DIR\" \\\n    --class_data_dir=\"$CLASS_DIR\" \\\n    --output_dir=\"$OUTPUT_DIR\" \\\n    --with_prior_preservation --prior_loss_weight=1.0 \\\n    --instance_prompt=\"$PT\"\\\n    --seed=$Seed \\\n    --resolution=$Res \\\n    --mixed_precision=$precision \\\n    --train_batch_size=1 \\\n    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n    --use_8bit_adam \\\n    --learning_rate=2e-6 \\\n    --lr_scheduler=\"polynomial\" \\\n    --lr_warmup_steps=0 \\\n    --max_train_steps=$Training_Steps \\\n    --num_class_images=200\n\ndef unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n  clear_output()\n  print('\u001b[1;33mTraining the unet...\u001b[0m')\n  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n    $Caption \\\n    --train_only_unet \\\n    --Session_dir=$SESSION_DIR \\\n    --save_starting_step=$stpsv \\\n    --save_n_steps=$stp \\\n    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n    --instance_data_dir=\"$INSTANCE_DIR\" \\\n    --output_dir=\"$OUTPUT_DIR\" \\\n    --instance_prompt=\"$PT\" \\\n    --seed=$Seed \\\n    --resolution=$Res \\\n    --mixed_precision=$precision \\\n    --train_batch_size=1 \\\n    --gradient_accumulation_steps=1 $GC \\\n    --use_8bit_adam \\\n    --learning_rate=2e-6 \\\n    --lr_scheduler=\"polynomial\" \\\n    --lr_warmup_steps=0 \\\n    --max_train_steps=$Training_Steps\n\nif Contains_faces!=\"No\":\n  \n  txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n  unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n\nelse:\n  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n    $Caption \\\n    $Textenc \\\n    --save_starting_step=$stpsv \\\n    --stop_text_encoder_training=$stptxt \\\n    --save_n_steps=$stp \\\n    --Session_dir=$SESSION_DIR \\\n    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n    --instance_data_dir=\"$INSTANCE_DIR\" \\\n    --output_dir=\"$OUTPUT_DIR\" \\\n    --instance_prompt=\"$PT\" \\\n    --seed=$Seed \\\n    --resolution=$Res \\\n    --mixed_precision=$precision \\\n    --train_batch_size=1 \\\n    --gradient_accumulation_steps=1 $GC \\\n    --use_8bit_adam \\\n    --learning_rate=2e-6 \\\n    --lr_scheduler=\"polynomial\" \\\n    --lr_warmup_steps=0 \\\n    --max_train_steps=$Training_Steps\n\n\nif os.path.exists('/kaggle/working/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n  print(\"Almost done ...\")\n  %cd /kaggle/working/content    \n  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n  clear_output()\n  if precision==\"no\":\n    !sed -i '226s@.*@@' /kaggle/working/content/convertosd.py\n  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /kaggle/working/content/convertosd.py\n  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /kaggle/working/content/convertosd.py\n  !python /kaggle/working/content/convertosd.py\n  clear_output()\n  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n      !cp -R '/kaggle/working/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n    print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n  else:\n    print(\"\u001b[1;31mSomething went wrong\")\n    \nelse:\n  print(\"\u001b[1;31mSomething went wrong\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cp /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/your_instance_name/your_instance_name.ckpt /kaggle/working","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'your_instance_name.ckpt')","metadata":{},"execution_count":null,"outputs":[]}]}