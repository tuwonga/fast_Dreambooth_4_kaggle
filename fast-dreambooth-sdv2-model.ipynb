{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/robertodefano/fast-dreambooth-sdv2-model?scriptVersionId=112365205\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-28T19:02:52.814371Z","iopub.status.busy":"2022-11-28T19:02:52.813939Z","iopub.status.idle":"2022-11-28T19:02:52.852293Z","shell.execute_reply":"2022-11-28T19:02:52.851222Z","shell.execute_reply.started":"2022-11-28T19:02:52.814288Z"}},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Find site-packages (note: can't be named site-packages)\n","from subprocess import getoutput\n","site_packages = getoutput('pip show torch')\n","site_packages = site_packages[site_packages.find('Location:')+10:]\n","site_packages = site_packages[:site_packages.find('\\n')]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:02:57.258256Z","iopub.status.busy":"2022-11-28T19:02:57.25791Z","iopub.status.idle":"2022-11-28T19:03:08.667647Z","shell.execute_reply":"2022-11-28T19:03:08.665699Z","shell.execute_reply.started":"2022-11-28T19:02:57.258225Z"}},"outputs":[],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-11-28T19:06:03.151274Z","iopub.status.busy":"2022-11-28T19:06:03.150747Z","iopub.status.idle":"2022-11-28T19:06:14.215627Z","shell.execute_reply":"2022-11-28T19:06:14.214368Z","shell.execute_reply.started":"2022-11-28T19:06:03.151233Z"}},"outputs":[],"source":["!pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:06:34.563127Z","iopub.status.busy":"2022-11-28T19:06:34.562462Z","iopub.status.idle":"2022-11-28T19:06:35.565938Z","shell.execute_reply":"2022-11-28T19:06:35.564629Z","shell.execute_reply.started":"2022-11-28T19:06:34.563085Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:06:38.22708Z","iopub.status.busy":"2022-11-28T19:06:38.2265Z","iopub.status.idle":"2022-11-28T19:06:39.220721Z","shell.execute_reply":"2022-11-28T19:06:39.219404Z","shell.execute_reply.started":"2022-11-28T19:06:38.227028Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:06:41.161969Z","iopub.status.busy":"2022-11-28T19:06:41.161555Z","iopub.status.idle":"2022-11-28T19:06:42.350376Z","shell.execute_reply":"2022-11-28T19:06:42.348935Z","shell.execute_reply.started":"2022-11-28T19:06:41.161936Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:06:44.490072Z","iopub.status.busy":"2022-11-28T19:06:44.489326Z","iopub.status.idle":"2022-11-28T19:06:44.498048Z","shell.execute_reply":"2022-11-28T19:06:44.496683Z","shell.execute_reply.started":"2022-11-28T19:06:44.49003Z"}},"outputs":[],"source":["%cd /kaggle/working/content"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:06:47.620803Z","iopub.status.busy":"2022-11-28T19:06:47.620363Z","iopub.status.idle":"2022-11-28T19:06:57.945584Z","shell.execute_reply":"2022-11-28T19:06:57.944408Z","shell.execute_reply.started":"2022-11-28T19:06:47.620771Z"}},"outputs":[],"source":["!pip install tensorflow-io-gcs-filesystem==0.21.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:10:08.918529Z","iopub.status.busy":"2022-11-28T19:10:08.918107Z","iopub.status.idle":"2022-11-28T19:10:18.718491Z","shell.execute_reply":"2022-11-28T19:10:18.71721Z","shell.execute_reply.started":"2022-11-28T19:10:08.918496Z"}},"outputs":[],"source":["!pip install google-cloud-bigquery-storage"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:10:26.325475Z","iopub.status.busy":"2022-11-28T19:10:26.324988Z","iopub.status.idle":"2022-11-28T19:12:20.500991Z","shell.execute_reply":"2022-11-28T19:12:20.499873Z","shell.execute_reply.started":"2022-11-28T19:10:26.325432Z"}},"outputs":[],"source":["!git clone --branch updt https://github.com/TheLastBen/diffusers\n","!pip install -q /kaggle/working/content/diffusers\n","!pip install -q accelerate==0.12.0\n","!pip install -q OmegaConf\n","!pip install -q wget\n","!pip install -q open_clip_torch\n","!pip install -q pillow==9\n","!pip install -q torchsde\n","!pip install -q pytorch_lightning\n","!pip install -q huggingface_hub\n","!pip install -U -q --no-cache-dir gdown\n","!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:13:06.948886Z","iopub.status.busy":"2022-11-28T19:13:06.948481Z","iopub.status.idle":"2022-11-28T19:13:12.45234Z","shell.execute_reply":"2022-11-28T19:13:12.451203Z","shell.execute_reply.started":"2022-11-28T19:13:06.948855Z"}},"outputs":[],"source":["!mv Deps Deps.7z\n","!7z x Deps.7z"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-11-28T19:13:37.707797Z","iopub.status.busy":"2022-11-28T19:13:37.706666Z","iopub.status.idle":"2022-11-28T19:13:39.132157Z","shell.execute_reply":"2022-11-28T19:13:39.130802Z","shell.execute_reply.started":"2022-11-28T19:13:37.707757Z"}},"outputs":[],"source":["!cp -r /kaggle/working/content/usr/local/lib/python3.7/dist-packages/* $site_packages --no-clobber"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:13:40.154118Z","iopub.status.busy":"2022-11-28T19:13:40.153733Z","iopub.status.idle":"2022-11-28T19:13:40.162481Z","shell.execute_reply":"2022-11-28T19:13:40.161435Z","shell.execute_reply.started":"2022-11-28T19:13:40.154085Z"}},"outputs":[],"source":["%cd /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:13:42.867367Z","iopub.status.busy":"2022-11-28T19:13:42.866825Z","iopub.status.idle":"2022-11-28T19:13:44.971869Z","shell.execute_reply":"2022-11-28T19:13:44.97048Z","shell.execute_reply.started":"2022-11-28T19:13:42.86732Z"}},"outputs":[],"source":["!rm /kaggle/working/content/Deps.7z\n","!rm -r /kaggle/working/content/usr"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:15:18.121278Z","iopub.status.busy":"2022-11-28T19:15:18.120803Z","iopub.status.idle":"2022-11-28T19:15:32.208067Z","shell.execute_reply":"2022-11-28T19:15:32.207035Z","shell.execute_reply.started":"2022-11-28T19:15:18.121237Z"}},"outputs":[],"source":["#@markdown # xformers\n","\n","from subprocess import getoutput\n","from IPython.display import HTML\n","from IPython.display import clear_output\n","import wget\n","import time\n","\n","s = getoutput('nvidia-smi')\n","if 'T4' in s:\n","  gpu = 'T4'\n","elif 'P100' in s:\n","  gpu = 'P100'\n","elif 'V100' in s:\n","  gpu = 'V100'\n","elif 'A100' in s:\n","  gpu = 'A100'\n","\n","while True:\n","    try: \n","        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n","        break\n","    except:\n","        pass\n","    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n","    time.sleep(5)\n","\n","if (gpu=='T4'):\n","  !pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n","  \n","elif (gpu=='P100'):\n","  !pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n","\n","elif (gpu=='V100'):\n","  !pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n","\n","elif (gpu=='A100'):\n","  !pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n","\n","clear_output()\n","print('\u001b[1;32mDONE !')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:18:14.22526Z","iopub.status.busy":"2022-11-28T19:18:14.224812Z","iopub.status.idle":"2022-11-28T19:18:14.23582Z","shell.execute_reply":"2022-11-28T19:18:14.23467Z","shell.execute_reply.started":"2022-11-28T19:18:14.225224Z"}},"outputs":[],"source":["%cd /kaggle/working/content"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:18:16.703725Z","iopub.status.busy":"2022-11-28T19:18:16.703339Z","iopub.status.idle":"2022-11-28T19:18:23.943923Z","shell.execute_reply":"2022-11-28T19:18:23.942772Z","shell.execute_reply.started":"2022-11-28T19:18:16.703694Z"}},"outputs":[],"source":["!sudo apt-get install git-lfs\n","!git lfs install"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:18:26.618221Z","iopub.status.busy":"2022-11-28T19:18:26.6178Z","iopub.status.idle":"2022-11-28T19:22:41.741365Z","shell.execute_reply":"2022-11-28T19:22:41.739669Z","shell.execute_reply.started":"2022-11-28T19:18:26.61819Z"}},"outputs":[],"source":["import os\n","import time\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","\n","#@markdown - Skip this cell if you are loading a previous session\n","\n","#@markdown ---\n","\n","Model_Version = \"V2-512px\" #@param [ \"1.5\", \"V2-512px\", \"V2-768px\"]\n","\n","#@markdown - Choose which version to finetune.\n","\n","#@markdown ---\n","\n","with capture.capture_output() as cap: \n","  %cd /kaggle/working/content/\n","\n","Huggingface_Token = \"your_huggingface_token\" #@param {type:\"string\"}\n","token=Huggingface_Token\n","\n","#@markdown - Leave EMPTY if you're using the v2 model.\n","#@markdown - Make sure you've accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5\n","\n","#@markdown ---\n","\n","Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n","\n","#@markdown - Load and finetune a model from Hugging Face, use the format \"profile/model\" like : runwayml/stable-diffusion-v1-5\n","\n","#@markdown Or\n","\n","CKPT_Path = \"\" #@param {type:\"string\"}\n","\n","#@markdown Or\n","\n","CKPT_Link = \"\" #@param {type:\"string\"}\n","\n","#@markdown - A CKPT direct link, huggingface CKPT link or a shared CKPT from gdrive.\n","#@markdown ---\n","\n","Compatibility_Mode=\"\" #@param {type:\"boolean\"}\n","#@markdown - Enable only if you're getting conversion errors.\n","\n","\n","def downloadmodel():\n","  token=Huggingface_Token\n","  if token==\"\":\n","      token=input(\"Insert your huggingface token :\")\n","  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n","    !rm -r /kaggle/working/content/stable-diffusion-v1-5\n","  clear_output()\n","\n","  %cd /kaggle/working/content/\n","  clear_output()\n","  !mkdir /kaggle/working/content/stable-diffusion-v1-5\n","  %cd /kaggle/working/content/stable-diffusion-v1-5\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  if os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n","    !mv /kaggle/working/content/stable-diffusion-v1-5/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-v1-5/vae\n","    !rm -r /kaggle/working/content/stable-diffusion-v1-5/.git\n","    %cd /kaggle/working/content/stable-diffusion-v1-5    \n","    !rm model_index.json\n","    time.sleep(1)    \n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","    !sed -i 's@\"clip_sample\": false@@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n","    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /kaggle/working/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n","    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /kaggle/working/content/stable-diffusion-v1-5/vae/config.json  \n","    %cd /kaggle/working/content/    \n","    clear_output()\n","    print('\u001b[1;32mDONE !')\n","  else:\n","    while not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n","         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n","         time.sleep(5)\n","\n","\n","def newdownloadmodel():\n","\n","  %cd /kaggle/working/content/\n","  clear_output()\n","  !mkdir /kaggle/working/content/stable-diffusion-v2-768\n","  %cd /kaggle/working/content/stable-diffusion-v2-768\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","    \n","    \n","def newdownloadmodelb():\n","\n","  %cd /kaggle/working/content/\n","  clear_output()\n","  !mkdir /kaggle/working/content/stable-diffusion-v2-512\n","  %cd /kaggle/working/content/stable-diffusion-v2-512\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2-base\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  clear_output()\n","  print('\u001b[1;32mDONE !')\n","    \n","    \n","if Path_to_HuggingFace != \"\":\n","  if os.path.exists('/kaggle/working/content/stable-diffusion-custom'):\n","    !rm -r /kaggle/working/content/stable-diffusion-custom\n","  clear_output()\n","  %cd /kaggle/working/content/\n","  clear_output()\n","  !mkdir /kaggle/working/content/stable-diffusion-custom\n","  %cd /kaggle/working/content/stable-diffusion-custom\n","  !git init\n","  !git lfs install --system --skip-repo\n","  !git remote add -f origin  \"https://USER:{token}@huggingface.co/{Path_to_HuggingFace}\"\n","  !git config core.sparsecheckout true\n","  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n","  !git pull origin main\n","  if os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n","    !mv /kaggle/working/content/stable-diffusion-custom/sd-vae-ft-mse /kaggle/working/content/stable-diffusion-custom/vae\n","    !rm -r /kaggle/working/content/stable-diffusion-custom/.git\n","    %cd /kaggle/working/content/stable-diffusion-custom\n","    !rm model_index.json\n","    time.sleep(1)\n","    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n","    !sed -i 's@\"clip_sample\": false@@g' /kaggle/working/content/stable-diffusion-custom/scheduler/scheduler_config.json\n","    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /kaggle/working/content/stable-diffusion-custom/scheduler/scheduler_config.json\n","    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /kaggle/working/content/stable-diffusion-custom/vae/config.json    \n","    %cd /kaggle/working/content/ \n","    MODEL_NAME=\"/kaggle/working/content/stable-diffusion-custom\"   \n","    clear_output()\n","    print('\u001b[1;32mDONE !')\n","  else:\n","    while not os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","          print('\u001b[1;31mCheck the link you provided')\n","          time.sleep(5)\n","\n","\n","\n","\n","elif CKPT_Path !=\"\":\n","  if os.path.exists('/kaggle/working/content/stable-custom'):\n","    !rm -r /kaggle/working/content/stable-diffusion-custom\n","  if os.path.exists(str(CKPT_Path)):\n","    !mkdir /kaggle/working/content/stable-diffusion-custom\n","    with capture.capture_output() as cap:\n","      if Compatibility_Mode:\n","        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n","        !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-custom\n","        !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n","      else:           \n","        !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /kaggle/working/content/stable-diffusion-custom\n","    if os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","      !rm /kaggle/working/content/v1-inference.yaml\n","      clear_output()\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-custom\"\n","      print('\u001b[1;32mDONE !')\n","    else:\n","      !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n","      !rm /kaggle/working/content/v1-inference.yaml\n","      !rm -r /kaggle/working/content/stable-diffusion-custom\n","      while not os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","        print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n","        time.sleep(5)\n","  else:\n","    while not os.path.exists(str(CKPT_Path)):\n","       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n","       time.sleep(5)\n","  \n","\n","\n","elif CKPT_Link !=\"\":   \n","    if os.path.exists('/kaggle/working/content/stable-diffusion-custom'):\n","      !rm -r /kaggle/working/content/stable-diffusion-custom   \n","    !gdown --fuzzy -O model.ckpt $CKPT_Link\n","    if os.path.exists('/kaggle/working/content/model.ckpt'):\n","      if os.path.getsize(\"/kaggle/working/content/model.ckpt\") > 1810671599:\n","        !mkdir /kaggle/working/content/stable-diffusion-custom\n","        with capture.capture_output() as cap: \n","          if Compatibility_Mode:\n","            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n","            !python /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-custom\n","            !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py            \n","          else:           \n","            !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /kaggle/working/content/model.ckpt --dump_path /kaggle/working/content/stable-diffusion-custom\n","        if os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","          clear_output()\n","          MODEL_NAME=\"/kaggle/working/content/stable-diffusion-custom\"\n","          print('\u001b[1;32mDONE !')\n","          !rm /kaggle/working/content/v1-inference.yaml\n","          !rm /kaggle/working/content/model.ckpt\n","        else:\n","          if os.path.exists('/kaggle/working/content/v1-inference.yaml'):\n","            !rm /kaggle/working/content/v1-inference.yaml\n","          !rm /kaggle/working/content/convert_original_stable_diffusion_to_diffusers.py\n","          !rm -r /kaggle/working/content/stable-diffusion-custom\n","          !rm /kaggle/working/content/model.ckpt\n","          while not os.path.exists('/kaggle/working/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n","            print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n","            time.sleep(5)\n","      else:\n","        while os.path.getsize('/kaggle/working/content/model.ckpt') < 1810671599:\n","           print('\u001b[1;31mWrong link, check that the link is valid')\n","           time.sleep(5)\n","    \n","\n","else:\n","  if Model_Version==\"1.5\":\n","    if not os.path.exists('/kaggle/working/content/stable-diffusion-v1-5'):\n","      downloadmodel()\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v1-5\"\n","    else:\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v1-5\"\n","      print(\"\u001b[1;32mThe v1.5 model already exist, using this model.\")\n","  elif Model_Version==\"V2-512px\":\n","    if not os.path.exists('/kaggle/working/content/stable-diffusion-v2-512'):\n","      newdownloadmodelb()\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v2-512\"\n","    else:\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v2-512\"\n","      print(\"\u001b[1;32mThe v2-512px model already exist, using this model.\")      \n","  elif Model_Version==\"V2-768px\":\n","    if not os.path.exists('/kaggle/working/content/stable-diffusion-v2-768'):   \n","      newdownloadmodel()\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v2-768\"\n","    else:\n","      MODEL_NAME=\"/kaggle/working/content/stable-diffusion-v2-768\"\n","      print(\"\u001b[1;32mThe v2-768px model already exist, using this model.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:22:46.728106Z","iopub.status.busy":"2022-11-28T19:22:46.72667Z","iopub.status.idle":"2022-11-28T19:22:47.702504Z","shell.execute_reply":"2022-11-28T19:22:47.700965Z","shell.execute_reply.started":"2022-11-28T19:22:46.728062Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:22:48.829812Z","iopub.status.busy":"2022-11-28T19:22:48.829421Z","iopub.status.idle":"2022-11-28T19:22:49.968933Z","shell.execute_reply":"2022-11-28T19:22:49.967547Z","shell.execute_reply.started":"2022-11-28T19:22:48.82978Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:22:50.845447Z","iopub.status.busy":"2022-11-28T19:22:50.844656Z","iopub.status.idle":"2022-11-28T19:22:51.841777Z","shell.execute_reply":"2022-11-28T19:22:51.839614Z","shell.execute_reply.started":"2022-11-28T19:22:50.845377Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:22:52.678078Z","iopub.status.busy":"2022-11-28T19:22:52.677198Z","iopub.status.idle":"2022-11-28T19:22:53.876742Z","shell.execute_reply":"2022-11-28T19:22:53.875272Z","shell.execute_reply.started":"2022-11-28T19:22:52.678024Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/instance_images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:22:57.541375Z","iopub.status.busy":"2022-11-28T19:22:57.540972Z","iopub.status.idle":"2022-11-28T19:22:58.59805Z","shell.execute_reply":"2022-11-28T19:22:58.596597Z","shell.execute_reply.started":"2022-11-28T19:22:57.541338Z"}},"outputs":[],"source":["!mkdir /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/Regularization_images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:23:39.054358Z","iopub.status.busy":"2022-11-28T19:23:39.05398Z","iopub.status.idle":"2022-11-28T19:23:40.57854Z","shell.execute_reply":"2022-11-28T19:23:40.577313Z","shell.execute_reply.started":"2022-11-28T19:23:39.054326Z"}},"outputs":[],"source":["import os\n","from IPython.display import clear_output\n","from IPython.utils import capture\n","from os import listdir\n","from os.path import isfile\n","import wget\n","import time\n","\n","#@markdown #Create/Load a Session\n","\n","try:\n","  MODEL_NAME\n","  pass\n","except:\n","  MODEL_NAME=\"\"\n","  \n","PT=\"\"\n","\n","Captionned_instance_images = True\n","\n","Session_Name = \"your_instance_name\" #@param{type: 'string'}\n","while Session_Name==\"\":\n","  print('\u001b[1;31mInput the Session Name:') \n","  Session_Name=input('')\n","Session_Name=Session_Name.replace(\" \",\"_\")\n","\n","#@markdown - Enter the session name, it if it exists, it will load it, otherwise it'll create an new session.\n","\n","Session_Link_optional = \"\" #@param{type: 'string'}\n","\n","#@markdown - Import a session from another gdrive, the shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove any intermediary CKPT if any.\n","\n","WORKSPACE='/kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth'\n","\n","if Session_Link_optional !=\"\":\n","  print('\u001b[1;32mDownloading session...')\n","with capture.capture_output() as cap:\n","  %cd /kaggle/working/content\n","  if Session_Link_optional != \"\":\n","    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n","      %mkdir -p $WORKSPACE'/Sessions'\n","      time.sleep(1)\n","    %cd $WORKSPACE'/Sessions'\n","    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n","    %cd $Session_Name\n","    !rm -r instance_images\n","    !rm -r Regularization_images\n","    !unzip instance_images.zip\n","    !mv *.ckpt $Session_Name\".ckpt\"\n","    %cd /kaggle/working/content\n","\n","\n","INSTANCE_NAME=Session_Name\n","OUTPUT_DIR=\"/kaggle/working/content/models/\"+Session_Name\n","SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n","INSTANCE_DIR=SESSION_DIR+'/instance_images'\n","MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n","CLASS_DIR=SESSION_DIR+'/Regularization_images'\n","\n","Contains_faces = \"No\" #@param [\"No\", \"Female\", \"Male\", \"Both\"]\n","\n","#@markdown - If you're training on a subject with a face or a movie/style that contains faces. (experimental, still needs some tuning) \n","\n","def reg():\n","  with capture.capture_output() as cap:\n","    if Contains_faces!=\"No\":\n","      if not os.path.exists(str(CLASS_DIR)):\n","        %mkdir -p \"$CLASS_DIR\"\n","      %cd $CLASS_DIR\n","      !rm -r Women Men Mix\n","      !wget -O Womenz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Women'\n","      !wget -O Menz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Men'\n","      !wget -O Mixz 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Mix'\n","      !unzip Menz\n","      !unzip Womenz\n","      !unzip Mixz\n","      !rm Menz Womenz Mixz\n","      !find . -name \"* *\" -type f | rename 's/ /_/g'\n","      %cd /kaggle/working/content               \n","\n","\n","if os.path.exists(str(SESSION_DIR)):\n","  if not os.path.exists(MDLPTH) and '.ckpt' in str([ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]):  \n","    \n","    def f(n):  \n","      k=0\n","      for i in [ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]:    \n","        if k==n:    \n","          !mv $SESSION_DIR/$i $MDLPTH\n","        k=k+1\n","\n","    k=0\n","    print('\u001b[1;33mNo final checkpoint model found, select which intermediary checkpoint to use (000 to skip):\\n\u001b[1;34m')\n","\n","    for i in [ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]:    \n","      print(str(k)+'- '+i)\n","      k=k+1\n","    n=input()\n","    while int(n)>k-1:\n","      n=input()  \n","    if n!=\"000\":\n","      f(int(n))\n","      print('\u001b[1;32mUsing the model '+ i+\" ...\")\n","      time.sleep(2)\n","    else:\n","      print('\u001b[1;32mSkipping the intermediary checkpoints.')\n","    del n\n","\n","\n","if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n","  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n","  reg()\n","  if MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  else:\n","    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n","\n","elif os.path.exists(MDLPTH):\n","  print('\u001b[1;32mSession found, loading the trained model ...')\n","  reg()\n","  %mkdir -p \"$OUTPUT_DIR\"\n","  !python /kaggle/working/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\" --session_dir \"$SESSION_DIR\"\n","  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","    resume=True    \n","    !rm /kaggle/working/content/v1-inference.yaml\n","    clear_output()\n","    print('\u001b[1;32mSession loaded.')\n","  else:     \n","    !rm /kaggle/working/content/v1-inference.yaml\n","    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n","\n","\n","elif not os.path.exists(str(SESSION_DIR)):\n","    %mkdir -p \"$INSTANCE_DIR\"\n","    print('\u001b[1;32mCreating session...')\n","    reg()\n","    if MODEL_NAME==\"\":\n","      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    else:\n","      print('\u001b[1;32mSession created, proceed to uploading instance images')\n","\n","    \n","if Contains_faces == \"Female\":\n","  CLASS_DIR=CLASS_DIR+'/Women'\n","if Contains_faces == \"Male\":\n","  CLASS_DIR=CLASS_DIR+'/Men'\n","if Contains_faces == \"Both\":\n","  CLASS_DIR=CLASS_DIR+'/Mix'\n","\n","try:\n","  Contain_f\n","  del Contain_f\n","except:\n","  pass\n","\n","    #@markdown \n","\n","    #@markdown # The most importent step is to rename the instance pictures of each subject to a unique unknown identifier, example :\n","    #@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n","    #@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:23:48.468872Z","iopub.status.busy":"2022-11-28T19:23:48.468502Z","iopub.status.idle":"2022-11-28T19:23:48.475492Z","shell.execute_reply":"2022-11-28T19:23:48.474453Z","shell.execute_reply.started":"2022-11-28T19:23:48.46884Z"}},"outputs":[],"source":["import shutil"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:23:51.331216Z","iopub.status.busy":"2022-11-28T19:23:51.330858Z","iopub.status.idle":"2022-11-28T19:23:51.338261Z","shell.execute_reply":"2022-11-28T19:23:51.336948Z","shell.execute_reply.started":"2022-11-28T19:23:51.331185Z"}},"outputs":[],"source":["from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:23:53.588663Z","iopub.status.busy":"2022-11-28T19:23:53.587385Z","iopub.status.idle":"2022-11-28T19:23:53.593744Z","shell.execute_reply":"2022-11-28T19:23:53.592517Z","shell.execute_reply.started":"2022-11-28T19:23:53.588626Z"}},"outputs":[],"source":["from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:24:38.74919Z","iopub.status.busy":"2022-11-28T19:24:38.748811Z","iopub.status.idle":"2022-11-28T19:24:40.316373Z","shell.execute_reply":"2022-11-28T19:24:40.315128Z","shell.execute_reply.started":"2022-11-28T19:24:38.749158Z"}},"outputs":[],"source":["!cp -r /kaggle/input/your_images_data_folder /kaggle/working/my"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:24:55.057497Z","iopub.status.busy":"2022-11-28T19:24:55.057097Z","iopub.status.idle":"2022-11-28T19:25:43.323302Z","shell.execute_reply":"2022-11-28T19:25:43.321879Z","shell.execute_reply.started":"2022-11-28T19:24:55.057463Z"}},"outputs":[],"source":["#@markdown #Instance Images\n","#@markdown ----\n","\n","#@markdown\n","#@markdown - Run the cell to Upload the instance pictures.\n","\n","Remove_existing_instance_images= True #@param{type: 'boolean'}\n","#@markdown - Uncheck the box to keep the existing instance images.\n","\n","\n","if Remove_existing_instance_images:\n","  if os.path.exists(str(INSTANCE_DIR)):\n","    !rm -r \"$INSTANCE_DIR\"\n","\n","if not os.path.exists(str(INSTANCE_DIR)):\n","  %mkdir -p \"$INSTANCE_DIR\"\n","\n","IMAGES_FOLDER_OPTIONAL=\"/kaggle/working/my\" #@param{type: 'string'}\n","\n","#@markdown - If you prefer to specify directly the folder of the pictures instead of uploading, this will add the pictures to the existing (if any) instance images. Leave EMPTY to upload.\n","\n","Crop_images= True #@param{type: 'boolean'}\n","Crop_size = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n","Crop_size=int(Crop_size)\n","\n","#@markdown - Unless you want to crop them manually in a precise way, you don't need to crop your instance images externally.\n","\n","while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n","  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n","  IMAGES_FOLDER_OPTIONAL=input('')\n","\n","if IMAGES_FOLDER_OPTIONAL!=\"\":\n","  if Crop_images:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      extension = filename.split(\".\")[1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):      \n","        side_length = min(width, height)\n","        left = (width - side_length)/2\n","        top = (height - side_length)/2\n","        right = (width + side_length)/2\n","        bottom = (height + side_length)/2\n","        image = file.crop((left, top, right, bottom))\n","        image = image.resize((Crop_size, Crop_size))\n","        if (extension.upper() == \"JPG\"):\n","            image.save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image.save(new_path_with_file, format=extension.upper())\n","      else:\n","        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n","\n","  else:\n","    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      !cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n"," \n","  print('\\n\u001b[1;32mDone, proceed to the training cell')\n","\n","\n","elif IMAGES_FOLDER_OPTIONAL ==\"\":\n","  uploaded = files.upload()\n","  if Crop_images:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      extension = filename.split(\".\")[1]\n","      identifier=filename.split(\".\")[0]\n","      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n","      file = Image.open(new_path_with_file)\n","      width, height = file.size\n","      if file.size !=(Crop_size, Crop_size):        \n","        side_length = min(width, height)\n","        left = (width - side_length)/2\n","        top = (height - side_length)/2\n","        right = (width + side_length)/2\n","        bottom = (height + side_length)/2\n","        image = file.crop((left, top, right, bottom))\n","        image = image.resize((Crop_size, Crop_size))\n","        if (extension.upper() == \"JPG\"):\n","            image.save(new_path_with_file, format=\"JPEG\", quality = 100)\n","        else:\n","            image.save(new_path_with_file, format=extension.upper())\n","      else:\n","          image.save(new_path_with_file, format=extension.upper())\n","      clear_output()\n","  else:\n","    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n","      shutil.move(filename, INSTANCE_DIR)\n","      clear_output()\n","\n","  print('\\n\u001b[1;32mDone, proceed to the training cell')\n","\n","with capture.capture_output() as cap:\n","  %cd \"$INSTANCE_DIR\"\n","  !find . -name \"* *\" -type f | rename 's/ /-/g'\n","  %cd /kaggle/working/content\n","  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n","    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"    \n","\n","  %cd $SESSION_DIR\n","  !rm instance_images.zip\n","  !zip -r instance_images instance_images\n","  %cd /kaggle/working/content"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:25:52.127343Z","iopub.status.busy":"2022-11-28T19:25:52.126297Z","iopub.status.idle":"2022-11-28T19:25:52.134763Z","shell.execute_reply":"2022-11-28T19:25:52.13368Z","shell.execute_reply.started":"2022-11-28T19:25:52.127295Z"}},"outputs":[],"source":["%cd /"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:25:54.821511Z","iopub.status.busy":"2022-11-28T19:25:54.821136Z","iopub.status.idle":"2022-11-28T19:26:12.749404Z","shell.execute_reply":"2022-11-28T19:26:12.748099Z","shell.execute_reply.started":"2022-11-28T19:25:54.821482Z"}},"outputs":[],"source":["!pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:26:12.752437Z","iopub.status.busy":"2022-11-28T19:26:12.752025Z","iopub.status.idle":"2022-11-28T19:26:23.002548Z","shell.execute_reply":"2022-11-28T19:26:23.001113Z","shell.execute_reply.started":"2022-11-28T19:26:12.752395Z"}},"outputs":[],"source":["!pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:26:50.908182Z","iopub.status.busy":"2022-11-28T19:26:50.907806Z","iopub.status.idle":"2022-11-28T19:27:01.265957Z","shell.execute_reply":"2022-11-28T19:27:01.264488Z","shell.execute_reply.started":"2022-11-28T19:26:50.908152Z"}},"outputs":[],"source":["!pip install ftfy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:27:01.269702Z","iopub.status.busy":"2022-11-28T19:27:01.26932Z","iopub.status.idle":"2022-11-28T19:27:14.914527Z","shell.execute_reply":"2022-11-28T19:27:14.913156Z","shell.execute_reply.started":"2022-11-28T19:27:01.269669Z"}},"outputs":[],"source":["!pip install bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:27:14.917632Z","iopub.status.busy":"2022-11-28T19:27:14.916742Z","iopub.status.idle":"2022-11-28T19:27:14.92842Z","shell.execute_reply":"2022-11-28T19:27:14.927433Z","shell.execute_reply.started":"2022-11-28T19:27:14.917585Z"}},"outputs":[],"source":["%cd /kaggle/working/content/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:27:31.875965Z","iopub.status.busy":"2022-11-28T19:27:31.875283Z","iopub.status.idle":"2022-11-28T19:27:31.880602Z","shell.execute_reply":"2022-11-28T19:27:31.879442Z","shell.execute_reply.started":"2022-11-28T19:27:31.875929Z"}},"outputs":[],"source":["import ftfy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-28T19:31:58.060341Z","iopub.status.busy":"2022-11-28T19:31:58.059907Z","iopub.status.idle":"2022-11-28T19:33:17.294129Z","shell.execute_reply":"2022-11-28T19:33:17.292737Z","shell.execute_reply.started":"2022-11-28T19:31:58.060308Z"}},"outputs":[],"source":["#@markdown ---\n","#@markdown #Start DreamBooth\n","#@markdown ---\n","import os\n","from subprocess import getoutput\n","from IPython.display import HTML\n","from IPython.display import clear_output\n","import time\n","import random\n","\n","Resume_Training = False #@param {type:\"boolean\"}\n","\n","while not Resume_Training and MODEL_NAME==\"\":\n","  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","  time.sleep(5)\n","\n","\n","#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n","\n","MODELT_NAME=MODEL_NAME\n","\n","Training_Steps=3000 #@param{type: 'number'}\n","#@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n","\n","Seed='' #@param{type: 'number'}\n","\n","#@markdown - Leave empty for a random seed.\n","\n","Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n","Res=int(Resolution)\n","\n","#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n","\n","Reduce_memory_usage = False #@param {type:\"boolean\"}\n","\n","fp16 = True #@param {type:\"boolean\"}\n","\n","#@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n","\n","#GC= \"\"\n","#if Resolution!=\"512\":\n","GC= \"--gradient_checkpointing\"\n","\n","if Seed =='' or Seed=='0':\n","  Seed=random.randint(1, 999999)\n","else:\n","  Seed=int(Seed)\n","\n","if fp16:\n","  prec=\"fp16\"\n","else:\n","  prec=\"no\"\n","\n","s = getoutput('nvidia-smi')\n","if 'A100' in s:\n","  precision=\"no\"\n","else:\n","  precision=prec\n","\n","try:\n","   resume\n","   if resume and not Resume_Training:\n","     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n","     while True:\n","        ansres=input('')\n","        if ansres=='no':\n","          Resume_Training = True\n","          del ansres\n","          break\n","        elif ansres=='yes':\n","          Resume_Training = False\n","          resume= False\n","          break\n","except:\n","  pass\n","\n","if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  MODELT_NAME=OUTPUT_DIR\n","  print('\u001b[1;32mResuming Training...\u001b[0m')\n","elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n","  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m')\n","  MODELT_NAME=MODEL_NAME\n","  while MODEL_NAME==\"\":\n","    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n","    time.sleep(5)\n","\n","#@markdown ---------------------------\n","\n","try:\n","   Contain_f\n","   pass\n","except:\n","   Contain_f=Contains_faces\n","\n","Enable_text_encoder_training= True #@param{type: 'boolean'}\n","\n","#@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n","#@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n","\n","#@markdown - Enter the % of the total steps for which to train the text_encoder\n","Train_text_encoder_for=100 #@param{type: 'number'}\n","\n","#@markdown - If you're training a style, keep it between 10-20%, if you're training on a person, set it between 50-70%, reduce it if you can't stylize the person/object.\n","#@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n","\n","if Train_text_encoder_for>=100:\n","  stptxt=Training_Steps\n","elif Train_text_encoder_for==0:\n","  Enable_text_encoder_training= False\n","  stptxt=10\n","else:\n","  stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n","\n","if not Enable_text_encoder_training:\n","  Contains_faces=\"No\"\n","else:\n","   Contains_faces=Contain_f\n","\n","if Enable_text_encoder_training:\n","  Textenc=\"--train_text_encoder\"\n","else:\n","  Textenc=\"\"\n","\n","#@markdown ---------------------------\n","Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n","Save_Checkpoint_Every=500 #@param{type: 'number'}\n","if Save_Checkpoint_Every==None:\n","  Save_Checkpoint_Every=1\n","#@markdown - Minimum 200 steps between each save.\n","stp=0\n","Start_saving_from_the_step=500 #@param{type: 'number'}\n","if Start_saving_from_the_step==None:\n","  Start_saving_from_the_step=0\n","if (Start_saving_from_the_step < 200):\n","  Start_saving_from_the_step=Save_Checkpoint_Every\n","stpsv=Start_saving_from_the_step\n","if Save_Checkpoint_Every_n_Steps:\n","  stp=Save_Checkpoint_Every\n","#@markdown - Start saving intermediary checkpoints from this step.\n","\n","Disconnect_after_training=False #@param {type:\"boolean\"}\n","\n","#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n","\n","Caption=''\n","if Captionned_instance_images:\n","  Caption='--image_captions_filename'\n","\n","\n","def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n","  print('\u001b[1;33mTraining the text encoder with regularization...\u001b[0m')\n","  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $Caption \\\n","    --train_text_encoder \\\n","    --dump_only_text_encoder \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --class_data_dir=\"$CLASS_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --with_prior_preservation --prior_loss_weight=1.0 \\\n","    --instance_prompt=\"$PT\"\\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n","    --use_8bit_adam \\\n","    --learning_rate=2e-6 \\\n","    --lr_scheduler=\"polynomial\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps \\\n","    --num_class_images=200\n","\n","def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n","  clear_output()\n","  print('\u001b[1;33mTraining the unet...\u001b[0m')\n","  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $Caption \\\n","    --train_only_unet \\\n","    --Session_dir=$SESSION_DIR \\\n","    --save_starting_step=$stpsv \\\n","    --save_n_steps=$stp \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 $GC \\\n","    --use_8bit_adam \\\n","    --learning_rate=2e-6 \\\n","    --lr_scheduler=\"polynomial\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","if Contains_faces!=\"No\":\n","  \n","  txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n","  unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n","\n","else:\n","  !accelerate launch /kaggle/working/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n","    $Caption \\\n","    $Textenc \\\n","    --save_starting_step=$stpsv \\\n","    --stop_text_encoder_training=$stptxt \\\n","    --save_n_steps=$stp \\\n","    --Session_dir=$SESSION_DIR \\\n","    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n","    --instance_data_dir=\"$INSTANCE_DIR\" \\\n","    --output_dir=\"$OUTPUT_DIR\" \\\n","    --instance_prompt=\"$PT\" \\\n","    --seed=$Seed \\\n","    --resolution=$Res \\\n","    --mixed_precision=$precision \\\n","    --train_batch_size=1 \\\n","    --gradient_accumulation_steps=1 $GC \\\n","    --use_8bit_adam \\\n","    --learning_rate=2e-6 \\\n","    --lr_scheduler=\"polynomial\" \\\n","    --lr_warmup_steps=0 \\\n","    --max_train_steps=$Training_Steps\n","\n","\n","if os.path.exists('/kaggle/working/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n","  print(\"Almost done ...\")\n","  %cd /content    \n","  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n","  clear_output()\n","  if precision==\"no\":\n","    !sed -i '226s@.*@@' /kaggle/working/content/convertosd.py\n","  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /kaggle/working/content/convertosd.py\n","  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /kaggle/working/content/convertosd.py\n","  !python /kaggle/working/content/convertosd.py\n","  clear_output()\n","  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n","    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n","      !cp -R '/kaggle/working/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n","    print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n","    if Disconnect_after_training :\n","      runtime.unassign()    \n","  else:\n","    print(\"\u001b[1;31mSomething went wrong\")\n","    \n","else:\n","  print(\"\u001b[1;31mSomething went wrong\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cp /kaggle/working/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/your_instance_name/your_instance_name.ckpt /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'your_instance_name.ckpt')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('python-env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e4aa31368adc1e672aa8d54d8517f837ba19bb89b8f889a2edc152335a4833cb"}}},"nbformat":4,"nbformat_minor":4}
